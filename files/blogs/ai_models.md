---
key: ai_models
title: Using AI as a Dev
tags:
    - jooasdf
    - jaksdfjl
    - jalskdfj
description: My personal thoughts on how AI is shaping the dev world from working at a startup.
---

AI seems to be this be-all end all development paradigm that's trying to shape the lives of devs across the globe.

IMO, this is just not happening. Working at a startup gives me pretty keen insight on how AI has affected the workplace. We're pretty AI first at eesel AI (obviously) so i think i have a fairly reasonable opinion on what the downsides are, the upsides, and where it's going.

---

## The upsides

### Learning tool

Ai as a learning tool is pretty much unbeatable. Complex system design patterns can be broken down and repeatedly drilled to understanding. Since it's powered by an LLM, the fear of having silly questions is pretty much non existent so you can actually just keep questioning even the fundamentals till you understand.

### Onboarding

AI can dramatically speed up the ability for a new developer to parse and understand a codebase. The ability to "speak" to your codebase is pretty transformative especially in smaller codebases. Idk how this would fare in a large codebase though, likely not well is my feeling.

I've personally seen devs grok concepts 10x faster due to AI.

### Composing Code

As i learnt more about the codebase and design patterns, tasks began to feel pretty obvious. Plans for issues already existed e2e in my head and the roadblock was actually writing the code.

I feel like AI is great for this sort of thing — just writing a bunch of code in super targeted places according to a plan i prescribe.

### Background Agents

These are pretty damn transformative, especially for product teams. No matter the scale i feel like bugs are pretty common and tend to have obvious solutions but there's a lot of them that just don't need to be fixed since it's not a priority cos the team has other stuff to do.

These fixes can simply be queued to background agents and let them run in the bg. Ofc the blocker pretty quickly tends to be the review overhead. You can get an AI to do a bunch of shit but nothing can be merged till it's validated to actually solve the problem and not break other stuff.

---

## The downsides

### Code Review

It's pretty apparent when code has been generated by AI tbh, at least in my opinion. Most of the time it isn't the code that's wrong per se — there wouldn't be any syntactical errors or any mistakes with the code quality.

I feel like fundamentally the design tends to be flawed though because AI is rather code happy. That's how LLMs work as next token predictors so things like reasoning etc are fundamentally just stopgaps to the obvious problem.

Ofc you can prevent this a lot by using something like plan mode and things like that but i feel like it doesn't really happen much. not sure why.

### Learning tool (again)

AI can also abstract literally everything from you to the point that the code looks like magic strings. This is pretty annoying.

It will introduce unnecesary concepts. In React i tend to see `useRef` used whenever component state needs to be controlled but the fundamental issue is the entire component hierarchy.

Regardless i feel like the abstraction is just fucked.

### The absttraction

The a

